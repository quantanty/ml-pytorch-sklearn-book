\subsection{Convolutional Neural Networks}
\begin{itemize}[topsep=0pt]
    \item CNNs mimic the human visual cortex and automatically learn features from raw data.
    \item Feature hierarchies: low-level features $\rightarrow$ high-level representations.
    \item Key ideas: \textbf{sparse connectivity} and \textbf{parameter sharing}.
    \item Pooling layers reduce spatial dimensions and help with generalization.
\end{itemize}

\subsection{Discrete Convolution}
\begin{align*}
y[i] &= \sum_{k=-\infty}^{+\infty} x[i-k] \cdot w[k] \\
Y[i,j] &= \sum_{k_1} \sum_{k_2} X[i-k_1, j-k_2] \cdot W[k_1, k_2]
\end{align*}

\noindent
Important hyperparameters: padding (full, same, valid), stride.

\subsection{Pooling Layers}
\begin{itemize}
    \item Max-pooling and mean-pooling.
    \item Improve robustness to noise, reduce overfitting.
    \item Can use overlapping or non-overlapping pooling.
\end{itemize}

\subsection{Loss Functions}
\begin{itemize}
    \item Binary classification: \texttt{BCEWithLogitsLoss}, \texttt{BCELoss}
    \item Multiclass: \texttt{CrossEntropyLoss}, \texttt{NLLLoss}
\end{itemize}