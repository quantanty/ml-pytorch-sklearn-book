{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2960080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length: 1112310\n",
      "Unique Characters: 80\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('../data/1268-0.txt', 'r', encoding='utf8') as fp:\n",
    "    text = fp.read()\n",
    "\n",
    "start_idx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_idx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_idx:end_idx]\n",
    "char_set = set(text)\n",
    "print('Total Length:', len(text))\n",
    "print('Unique Characters:', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d789eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape: (1112310,)\n",
      "THE MYSTERIOUS  == Encoding ==> [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28] == Reversse ==> ISLAND\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
    "print('Text encoded shape:', text_encoded.shape)\n",
    "print(text[:15], '== Encoding ==>', text_encoded[:15])\n",
    "print(text_encoded[15:21], '== Reversse ==>', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682005b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    }
   ],
   "source": [
    "for ex in text_encoded[:5]:\n",
    "    print('{} -> {}'.format(ex, char_array[ex]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca64c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44 32 29  1 37 48 43 44 29 42 33 39 45 43  1 33 43 36 25 38 28  0  0 51\n",
      " 74  1 34 70 61 54 68  1 46 54 67 63 54  0  0 12] -> 19\n",
      "'THE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n1'  ->  '8'\n"
     ]
    }
   ],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "text_chunks = [text_encoded[i:i+chunk_size] for i in range(len(text_encoded) - chunk_size)]\n",
    "\n",
    "for seq in text_chunks[:1]:\n",
    "    input_seq = seq[:seq_length]\n",
    "    target = seq[seq_length]\n",
    "    print(input_seq, '->', target)\n",
    "    print(repr(''.join(char_array[input_seq])), \n",
    "          ' -> ', repr(''.join(char_array[target])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d998a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text_chunk = self.text_chunks[idx]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "\n",
    "seq_dataset = TextDataset(torch.tensor(np.array(text_chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89b8ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (x):\n",
      "'THE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n1'\n",
      "Target (y):\n",
      "'HE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n18'\n",
      "\n",
      "Input (x):\n",
      "'HE MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n18'\n",
      "Target (y):\n",
      "'E MYSTERIOUS ISLAND\\n\\nby Jules Verne\\n\\n187'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decode = lambda mask: repr(''.join(char_array[mask]))\n",
    "\n",
    "for i, (seq, target) in enumerate(seq_dataset):\n",
    "    print('Input (x):\\n%s' % (decode(seq)))\n",
    "    print('Target (y):\\n%s' % (decode(target)))\n",
    "    print()\n",
    "    \n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3cdec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1165c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c284a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden.to(device), cell.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c791b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(80, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=80, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c1e5cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.3720\n",
      "Epoch 500 loss: 1.5593\n",
      "Epoch 1000 loss: 1.3769\n",
      "Epoch 1500 loss: 1.3499\n",
      "Epoch 2000 loss: 1.2380\n",
      "Epoch 2500 loss: 1.1904\n",
      "Epoch 3000 loss: 1.1461\n",
      "Epoch 3500 loss: 1.1644\n",
      "Epoch 4000 loss: 1.1000\n",
      "Epoch 4500 loss: 1.1095\n",
      "Epoch 5000 loss: 1.0973\n",
      "Epoch 5500 loss: 1.0847\n",
      "Epoch 6000 loss: 1.0589\n",
      "Epoch 6500 loss: 1.0919\n",
      "Epoch 7000 loss: 1.0441\n",
      "Epoch 7500 loss: 1.0409\n",
      "Epoch 8000 loss: 1.0405\n",
      "Epoch 8500 loss: 1.0644\n",
      "Epoch 9000 loss: 1.0320\n",
      "Epoch 9500 loss: 1.0395\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10000\n",
    "torch.manual_seed(1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dl))\n",
    "    seq_batch = seq_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item()/seq_length\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch} loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59bf6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/ch15-rnn-v1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8364272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities: [0.33333334 0.33333334 0.33333334]\n"
     ]
    }
   ],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "torch.manual_seed(1)\n",
    "logits = torch.tensor([[1.0, 1.0, 1.0]])\n",
    "print('probabilities:', nn.functional.softmax(logits, dim=1).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7b3d597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0120ac59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities: [0.10650698 0.10650698 0.78698605]\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([[1.0, 1.0, 3.0]])\n",
    "print('probabilities:', nn.functional.softmax(logits, dim=1).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4989fba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "m = Categorical(logits=logits)\n",
    "samples = m.sample((10,))\n",
    "print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04b4f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, starting_str, len_generated_text=500, scale_factor=1.0):\n",
    "    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n",
    "    encoded_input = torch.reshape(encoded_input, (1, -1)).to(device)\n",
    "    generated_str = starting_str\n",
    "    \n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(encoded_input[:, c].view(1), hidden, cell)\n",
    "\n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(last_char.view(1), hidden, cell)\n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(char_array[last_char])\n",
    "\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c3dff8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But what was a complete sure of\n",
      "the mystery which had been so establiquely. Pencroft, with intending to hoist emotion to all.\n",
      "\n",
      "Towards six, Cyrus Harding, “whered are the precious verous time to Cyrus Harding’s inhabited; there even intended to survey the cost of the corral.\n",
      "\n",
      "The six hard later stopped, and then returned to the bay, which were watercourses of our new feet nor their feasts were gazing at the southern part of the ladder--a\n",
      "right by the fine season whose branches was habitable to remain power \n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(4)\n",
    "print(sample(model, starting_str='But what was'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cb98c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But what was a man of the convicts which should be done in a certainty incident work. The sides of the northern\n",
      "point of the island, and the temperature was not a continent would be to be done but to be feared, the wind had discovered the winter of the plants were to be seen that some days after the\n",
      "most proposed to be desired. The reporter and his companions had not been so stretched on the shore, so that the sea\n",
      "was a man of five minutes to the bottom of the well, which were all was there that he was acco\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(4)\n",
    "print(sample(model, starting_str='But what was', scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7108ed7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But what was alive Linnarius gated vike is quelush. Sear had cestwaPequescollemple, but I0 isten\n",
      "an thinkon-shelong. All alt.\n",
      "Beoked quift, “you Cyre, cay make baddering! Where, perhrope,--tying Chasked hee\n",
      "as! ” could I; sed fiers-hot.”\n",
      "\n",
      "It had hearpy, did shop why, my bong-maYiqsies. Would sy, my oughezo;\n",
      "thenvery,”o observed.\n",
      "\n",
      "Come? It wishtwayed? Looks:-”0\n",
      "\n",
      "Gineer; alfood awlique alypew.,--gazigh Prospearos.--\n",
      "\n",
      "\n",
      "“Or, Pencroft!” send hidoxed thing; fnew effere?s\n",
      "frequented fruith by seas hairwapses Ra’cv\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(4)\n",
    "print(sample(model, starting_str='But what was', scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6461a9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which implement the neural network and strewn house, and then so as to be unable to established, the positive passage had then finished, and the trees were laid on the 25th of\n",
      "March, and they were about to sent them to the 15th of February, the colonists were not to be destroyed some embarking nearly swiftly on the 17th of August, and as hope themselves with the sailor’s name. There was\n",
      "not a communication between the southern part of the day before and the presence of new fire was necessary to reach the bay, as they had suppose\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(4)\n",
    "print(sample(model, starting_str='which implement the neural network', scale_factor=1.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
