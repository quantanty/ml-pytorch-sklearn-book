{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 772,
     "status": "ok",
     "timestamp": 1750660607158,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "Bl3806Nf-LRe",
    "outputId": "6ac83308-cd97-4adf-ddeb-99352a490648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ml-pytorch-sklearn-book' already exists and is not an empty directory.\n",
      "/content/ml-pytorch-sklearn-book\n",
      "remote: Enumerating objects: 9, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 5 (delta 4), reused 5 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (5/5), 412 bytes | 412.00 KiB/s, done.\n",
      "From https://github.com/quantanty/ml-pytorch-sklearn-book\n",
      "   0000213..58d2fd5  practice/ch15-B -> origin/practice/ch15-B\n",
      "Already on 'practice/ch15-B'\n",
      "Your branch is behind 'origin/practice/ch15-B' by 1 commit, and can be fast-forwarded.\n",
      "  (use \"git pull\" to update your local branch)\n",
      "/content/ml-pytorch-sklearn-book/ch15\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/quantanty/ml-pytorch-sklearn-book.git\n",
    "# %cd /content/ml-pytorch-sklearn-book/\n",
    "# !git fetch\n",
    "# !git checkout practice/ch15-B\n",
    "# %cd ch15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1750660613129,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "vBBLQ-XlYXR3",
    "outputId": "f375e027-89df-4b96-daab-db7ecbde213b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/ml-pytorch-sklearn-book\n",
      "From https://github.com/quantanty/ml-pytorch-sklearn-book\n",
      " * branch            practice/ch15-B -> FETCH_HEAD\n",
      "Updating 0000213..58d2fd5\n",
      "Fast-forward\n",
      " ch15/utils/model.py | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
      " 1 file changed, 2 insertions(+), 2 deletions(-)\n",
      "/content/ml-pytorch-sklearn-book/ch15\n"
     ]
    }
   ],
   "source": [
    "# %cd /content/ml-pytorch-sklearn-book/\n",
    "# !git pull origin practice/ch15-B\n",
    "# %cd ch15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1750661204554,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "Ba-ALXV3NZnp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1594,
     "status": "ok",
     "timestamp": 1750660623865,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "KTE6r6scErvs",
    "outputId": "994b0d59-a783-4895-be9e-b4891e8a862e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/quan-pham/Documents/Study/MLPytorch/ch15/utils/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1750661184179,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "0x2IKyj6Et4P"
   },
   "outputs": [],
   "source": [
    "start = 'THE MYSTERIOUS ISLAND'\n",
    "end = '\\n\\n*** END OF THE PROJECT GUTENBERG'\n",
    "# mys_dataset = utils.data.MysteriousIsland('/content/drive/MyDrive/Machine Learning/data/1268-0.txt', 41, start, end)\n",
    "mys_dataset = utils.data.MysteriousIsland('../data/1268-0.txt', 41, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 64,
     "status": "ok",
     "timestamp": 1750661200755,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "3mthiT4INsCQ"
   },
   "outputs": [],
   "source": [
    "train_set, test_set = utils.data.split_dataset(mys_dataset, train_size=0.4)\n",
    "batch_size = 64\n",
    "train_dl = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750660639420,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "Ji7vpfnaN9O7"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(mys_dataset.int2char)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "torch.manual_seed(555)\n",
    "model = utils.model.RNN_v1(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1750660641061,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "v9Bieg0COdOF",
    "outputId": "a39d2099-255f-42c6-d33b-0a336e2522be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_v1(\n",
       "  (embedding): Embedding(79, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=79, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('/content/gen-v1.pth'))\n",
    "model.load_state_dict(torch.load('../models/gen-v1.pth'))\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1750660653284,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "7H8VdCUhPjk_"
   },
   "outputs": [],
   "source": [
    "from torch.distributions.categorical import Categorical\n",
    "import numpy as np\n",
    "c2i = mys_dataset.char2int\n",
    "i2c = mys_dataset.int2char\n",
    "encode, decode = mys_dataset.get_encoder_decoder()\n",
    "\n",
    "def sample(model, starting_str, len_generated_text=500, scale_factor=1.0):\n",
    "    encoded_input = torch.tensor([c2i[s] for s in starting_str])\n",
    "    encoded_input = torch.reshape(encoded_input, (1, -1)).to(device)\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    hidden = hidden.to(device)\n",
    "    cell = cell.to(device)\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(encoded_input[:, c].view(1), hidden, cell)\n",
    "\n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(last_char.view(1), hidden, cell)\n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        generated_str += str(i2c[last_char])\n",
    "\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1750660679069,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "Hq44flErQAnL",
    "outputId": "40d21522-5546-45fe-d3d1-e628eaadb844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mysterious animal, the productions of the first part of the river, and the reporter listened to the long slowly, and the tempest gave a few moments the sailor was probable that some accident\n",
      "of the powder-magazine. The reporter returned to Granite House.\n",
      "\n",
      "The settlers had been seen from the sea.\n",
      "\n",
      "Ayrton to fear the reporter’s companions. The shore was thus face the left bank of the Mercy, and leaving the lake was returned, were to be done but to return to the river, which would be always reached the water\n"
     ]
    }
   ],
   "source": [
    "print(sample(model, starting_str='The mysterious', scale_factor=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1750661280812,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "Q2pGpL6rhjDL",
    "outputId": "59c088e2-afa4-44bf-de5e-d467818bae1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_v2(\n",
       "  (embedding): Embedding(79, 128)\n",
       "  (rnn): LSTM(128, 512, batch_first=True, bidirectional=True)\n",
       "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=1024, out_features=79, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RNN_v2(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=128, rnn_hidden_size=512, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, num_layers=num_layers, bidirectional=True, batch_first=True)\n",
    "        self.layer_norm = nn.LayerNorm(2*rnn_hidden_size)\n",
    "        self.fc = nn.Linear(2*rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.layer_norm(out)\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(2, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(2, batch_size, self.rnn_hidden_size)\n",
    "        return hidden, cell\n",
    "\n",
    "model_2 = RNN_v2(vocab_size)\n",
    "model_2 = model_2.to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = len(mys_dataset.chunks[0]) - 1\n",
    "def train(model, dl, loss_fn, optimizer, num_epochs):\n",
    "    milestone_length = 500\n",
    "    epoch_ranges = [(0, 1), (1, milestone_length)] + [(i, i+milestone_length) for i in range(milestone_length, num_epochs, milestone_length)]\n",
    "\n",
    "    for i, (start_epoch, end_epoch) in enumerate(epoch_ranges):\n",
    "        loss: float\n",
    "        for epoch in range(start_epoch, end_epoch):\n",
    "            hidden, cell = model.init_hidden(batch_size)\n",
    "            hidden = hidden.to(device)\n",
    "            cell = cell.to(device)\n",
    "            seq_batch, target_batch = next(iter(dl))\n",
    "            seq_batch = seq_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = 0\n",
    "            for c in range(seq_length):\n",
    "                pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "                loss += loss_fn(pred, target_batch[:, c])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss = loss.item()/seq_length\n",
    "\n",
    "        print(f'epoch {epoch:4d} loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 639101,
     "status": "ok",
     "timestamp": 1750661921469,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "57d1nviSdXhh",
    "outputId": "48590a96-c359-493c-9830-de0a77d39e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 loss: 4.466468429565429\n",
      "epoch  499 loss: 1.3365333557128907\n",
      "epoch  999 loss: 1.2513358116149902\n",
      "epoch 1499 loss: 1.1688644409179687\n",
      "epoch 1999 loss: 1.1567015647888184\n",
      "epoch 2499 loss: 1.1062256813049316\n",
      "epoch 2999 loss: 1.0191046714782714\n",
      "epoch 3499 loss: 0.9999540328979493\n",
      "epoch 3999 loss: 0.9570250511169434\n",
      "epoch 4499 loss: 0.9450458526611328\n",
      "epoch 4999 loss: 0.971148681640625\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=0.001)\n",
    "\n",
    "train(model_2, train_dl, loss_fn, optimizer, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1750660720798,
     "user": {
      "displayName": "quân phạm",
      "userId": "13087667620226477406"
     },
     "user_tz": -420
    },
    "id": "pEyHY9UJaF7s",
    "outputId": "47b7914b-6ae5-4b8b-c3a1-ad7837eaa097"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_v2(\n",
       "  (embedding): Embedding(79, 128)\n",
       "  (rnn): LSTM(128, 512, batch_first=True, bidirectional=True)\n",
       "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=1024, out_features=79, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_1 = utils.model.RNN_v2(vocab_size)\n",
    "model_2_1 = model_2_1.to(device)\n",
    "model_2_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = len(mys_dataset.chunks[0]) - 1\n",
    "def train_batch(model, dl, loss_fn, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = 0\n",
    "        \n",
    "        for i, (seq_batch, target_batch) in enumerate(dl):\n",
    "            hidden, cell = model.init_hidden(dl.batch_size)\n",
    "            hidden = hidden.to(device)\n",
    "            cell = cell.to(device)\n",
    "            seq_batch = seq_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss_batch = 0\n",
    "            for c in range(seq_length):\n",
    "                pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "                loss_batch += loss_fn(pred, target_batch[:, c])\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            loss += loss_batch.item() / seq_length\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                print(f'batch {i:4d}\\tloss: {loss / (i+1)}')\n",
    "        \n",
    "        loss /= len(dl)\n",
    "\n",
    "        print(f'epoch {epoch:4d})\\tloss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch    0\tloss: 4.4457141876220705\n",
      "batch  500\tloss: 1.6548116918095566\n",
      "batch 1000\tloss: 1.4747299299135335\n",
      "batch 1500\tloss: 1.3828511717159089\n",
      "batch 2000\tloss: 1.3221959203675304\n",
      "batch 2500\tloss: 1.2779088856934664\n",
      "batch 3000\tloss: 1.2425471702761282\n",
      "batch 3500\tloss: 1.2128794192042032\n",
      "batch 4000\tloss: 1.1872820041144516\n",
      "batch 4500\tloss: 1.164249623274704\n",
      "batch 5000\tloss: 1.1437394311298887\n",
      "batch 5500\tloss: 1.1246847383110483\n",
      "batch 6000\tloss: 1.107233327834773\n",
      "batch 6500\tloss: 1.0909475824719617\n",
      "epoch    0)\tloss: 69.31913240485731\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_2_1.parameters(), lr=0.001)\n",
    "\n",
    "train_batch(model_2_1, train_dl, loss_fn, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mysterious being, who\n",
      "uninhabited, of the convicts, boiltry-yard and the apparatus. “We must consider\n",
      "the expedition to those of the Mercy. It would not be better than two companions arrived at the\n",
      "bottom of the sea.\n",
      "\n",
      "“There is no longer any means of the southern point of the\n",
      "islet, with the aid of the alarm had evidently fallen to the sea the sailor he had not as yet each eight o’clock in the morning, the presence of the promontory, although he shared the colonists, could not see the sailor and Gideon Sp\n"
     ]
    }
   ],
   "source": [
    "print(sample(model_2_1, \"the mysterious\", scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_2, test_test_2 = utils.data.split_dataset(test_set, train_size=0.2)\n",
    "train_dl_2 = DataLoader(train_set_2, batch_size, shuffle=True, drop_last=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_2_1.state_dict(), '../models/gen-v2.1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch    0\tloss: 0.9061808586120605\n",
      "batch  500\tloss: 0.8584881321874681\n",
      "batch 1000\tloss: 0.8497989320612099\n",
      "batch 1500\tloss: 0.8413363224502262\n",
      "batch 2000\tloss: 0.8333709676285984\n",
      "epoch    0)\tloss: 0.8321314360483669\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_2_1.parameters(), lr=0.001)\n",
    "\n",
    "train_batch(model_2_1, train_dl_2, loss_fn, optimizer, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clock clock clock clocked balls through the forest, the sea having been convinced that the engineer had not\n",
      "been deceived until he might have been able to discover the aspect of the islet at the mouth of Falls River. There they began to come without their having had any idea of the colonists would have been made to him.\n",
      "\n",
      "“Gentlemen,” he said, “Herbert, who was then lighted up the ladder.”\n",
      "\n",
      "“Spilett,” answered the engineer.\n",
      "\n",
      "“Quite my opinion.”\n",
      "\n",
      "“And when you have said that the intelligent animal works cast with the se\n"
     ]
    }
   ],
   "source": [
    "print(sample(model_2_1, \"clock clock clock clock\", scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_2_1.state_dict(), '../models/gen-v2.2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_v2(\n",
       "  (embedding): Embedding(79, 128)\n",
       "  (rnn): LSTM(128, 512, batch_first=True, bidirectional=True)\n",
       "  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=1024, out_features=79, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = utils.model.RNN_v2(vocab_size)\n",
    "model_2.load_state_dict(torch.load('../models/gen-v2.2.pth'))\n",
    "model_2 = model_2.to(device)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clock clock clock clocks. A few trees, where the boat was not in the same material.\n",
      "\n",
      "It was the stranger was ready, and which might be left for at any cost to a thousand questions of the engineer.\n",
      "\n",
      "“Well, captain,” replied the sailor, “there is the matter, the return of day, and also that the declivity of the animal would be\n",
      "sufficient to convey it to the coast of the island was rather, the case was employed in the western shore of Lake Grant; worked with a powerful being, and it was agreed that the settlers in Lincol\n"
     ]
    }
   ],
   "source": [
    "print(sample(model_2, \"clock clock clock clock\", scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def eval(model, dl, loss_fn):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for seq_batch, target_batch in tqdm(dl):\n",
    "            hidden, cell = model.init_hidden(dl.batch_size)\n",
    "            hidden = hidden.to(device)\n",
    "            cell = cell.to(device)\n",
    "            seq_batch = seq_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "            loss_batch = 0\n",
    "            for c in range(seq_length):\n",
    "                pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "                loss_batch += loss_fn(pred, target_batch[:, c])\n",
    "            loss += loss_batch.item() / seq_length\n",
    "    \n",
    "    return loss / len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8341/8341 [04:07<00:00, 33.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8036209054994238"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl = DataLoader(test_test_2, batch_size, shuffle=None, drop_last=True, num_workers=4)\n",
    "test_loss = eval(model_2, test_dl, loss_fn)\n",
    "test_loss"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMIFn7Z/SyAjjy96j1M0I8K",
   "gpuType": "T4",
   "mount_file_id": "1kx4DQIp0CuyTt-NlJGx5c6iTIw4k2PSp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
